<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>dremio | reimagining data analytics for the modern world</title>
    <link>kstirman.github.io/bookshelf/categories/google-analytics/index.xml</link>
    <description>Recent content on dremio | reimagining data analytics for the modern world</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <atom:link href="kstirman.github.io/bookshelf/categories/google-analytics/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Querying Google Analytics JSON with a custom SQL function</title>
      <link>/kstirman.github.io/bookshelf/blog/querying-google-analytics-JSON-with-a-custom-SQL-function/</link>
      <pubDate>Fri, 30 Oct 2015 00:00:00 +0000</pubDate>
      
      <guid>/kstirman.github.io/bookshelf/blog/querying-google-analytics-JSON-with-a-custom-SQL-function/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;kstirman.github.io/bookshelf/blog/using-sql-to-interface-with-google-analytics-data-stored-on-amazon-s3/&#34;&gt;Last time&lt;/a&gt; I wrapped up
by showing you how to look at Google Analytics JSON using a nested SQL query in Apache Drill.  This approach is fine,
but by implementing a custom function in Drill we can talk to the same data using a much simpler query.&lt;/p&gt;

&lt;p&gt;To get started making user defined functions (UDFs), you first need to download and install &lt;a href=&#34;https://maven.apache.org/download.cgi&#34;&gt;Apache
Maven&lt;/a&gt;. Once you have the tarball, move it to your home directory, and then do:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;tar xzvf apache-maven-3.3.3-bin.tar.gz
mv apache-maven-3.3.3 apache-maven
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You should also put Maven&amp;rsquo;s &lt;code&gt;bin&lt;/code&gt; directory in your system path, so add the line&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;export PATH=$PATH:~/apache-maven/bin
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;to the end of your &lt;code&gt;.bashrc&lt;/code&gt; or &lt;code&gt;.bash_profile&lt;/code&gt; file. Next we need to create a new project in Maven for our custom
function. You can do this by issuing a command like:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;mvn archetype:generate -DgroupId=com.yourgroupidentifier.udf -DartifactId=gahelper -DinteractiveMode=false
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;in whatever folder you prefer to store the project. We&amp;rsquo;re going to call our Google Analytics helper function GAHELPER(),
although you&amp;rsquo;re free to call it whatever you prefer (in fact, FRANK() has a nice ring to it). Now cd to the &amp;lsquo;gahelper&amp;rsquo;
(or &amp;lsquo;frank&amp;rsquo;!) directory, and open up the configuration file for the project: &lt;code&gt;pom.xml&lt;/code&gt;. Add the following new dependecy
under the &lt;code&gt;&amp;lt;dependencies&amp;gt;&lt;/code&gt; XML tag:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;dependency&amp;gt;
  &amp;lt;groupId&amp;gt;org.apache.drill.exec&amp;lt;/groupId&amp;gt;
  &amp;lt;artifactId&amp;gt;drill-java-exec&amp;lt;/artifactId&amp;gt;
  &amp;lt;version&amp;gt;1.2.0&amp;lt;/version&amp;gt;
&amp;lt;/dependency&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Then place this block one level under the main &lt;code&gt;&amp;lt;project&amp;gt;&lt;/code&gt; tag:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;build&amp;gt;
  &amp;lt;plugins&amp;gt;
    &amp;lt;plugin&amp;gt;
      &amp;lt;groupId&amp;gt;org.apache.maven.plugins&amp;lt;/groupId&amp;gt;
      &amp;lt;artifactId&amp;gt;maven-source-plugin&amp;lt;/artifactId&amp;gt;
      &amp;lt;version&amp;gt;2.4&amp;lt;/version&amp;gt;
      &amp;lt;executions&amp;gt;
        &amp;lt;execution&amp;gt;
          &amp;lt;id&amp;gt;attach-sources&amp;lt;/id&amp;gt;
          &amp;lt;phase&amp;gt;package&amp;lt;/phase&amp;gt;
          &amp;lt;goals&amp;gt;
            &amp;lt;goal&amp;gt;jar-no-fork&amp;lt;/goal&amp;gt;
          &amp;lt;/goals&amp;gt;
        &amp;lt;/execution&amp;gt;
      &amp;lt;/executions&amp;gt;
    &amp;lt;/plugin&amp;gt;
  &amp;lt;/plugins&amp;gt;
&amp;lt;/build&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Before we start messing with the actual code of the project, we need to do one last thing so that Drill knows
to treat what we&amp;rsquo;re making as a function we can use in queries. Make this folder from within the base directory of your
project (the one that has &lt;code&gt;pom.xml&lt;/code&gt; in it):&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;mkdir ./src/main/resources
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And then create the file &lt;code&gt;./src/main/resources/drill-module.conf&lt;/code&gt;, and fill it with this configuration text:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;drill {
  classpath.scanning {
    packages : ${?drill.classpath.scanning.packages} [
      com.yourgroupidentifier.udf
    ]
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Okay: Time to check out some UDF source code! Go to the project&amp;rsquo;s &lt;code&gt;src/main/java/com/yourgroupidentifier/udf&lt;/code&gt;
directory, delete &lt;code&gt;App.java&lt;/code&gt;, and create a new file named &lt;code&gt;gaHelper.java&lt;/code&gt;. Paste in the following source (note that the
package name listed here should be the same as the one given in the &lt;code&gt;drill-module.conf&lt;/code&gt; file we just made):&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;// This software is covered under the Apache 2.0 license
// Read here: http://www.apache.org/licenses/LICENSE-2.0

package com.yourgroupidentifier.udf;

import org.apache.drill.exec.expr.DrillSimpleFunc;

import org.apache.drill.exec.expr.annotations.FunctionTemplate;
import org.apache.drill.exec.expr.annotations.Param;
import org.apache.drill.exec.expr.annotations.Output;

import org.apache.drill.exec.vector.complex.reader.FieldReader;

import io.netty.buffer.DrillBuf;
import org.apache.drill.exec.vector.complex.writer.BaseWriter;

import javax.inject.Inject;

@FunctionTemplate(name=&amp;quot;gahelper&amp;quot;, scope=FunctionTemplate.FunctionScope.SIMPLE, nulls=FunctionTemplate.NullHandling.NULL_IF_NULL)

public class gaHelper implements DrillSimpleFunc {

  @Param FieldReader columnsArray;
  @Param FieldReader rowArray;

  @Output BaseWriter.ComplexWriter outWriter;

  @Inject DrillBuf outBuffer;

  public void setup() {}

  public void eval() {

    org.apache.drill.exec.vector.complex.writer.BaseWriter.MapWriter gaMapWriter = outWriter.rootAsMap();

    // Index used to iterate over the &#39;rows&#39; entries
    Integer i = 0;

    // Work through &#39;columnHeaders&#39; list, lining it up with the fields in a &#39;rows&#39; entry
    while(columnsArray.next()) {

      // Pull name and type information about the column
      String colNameString = columnsArray.reader(&amp;quot;name&amp;quot;).readText().toString();
      String colTypeString = columnsArray.reader(&amp;quot;dataType&amp;quot;).readText().toString();

      // And the corresponding entry from the &#39;rows&#39; list
      String rowString = rowArray.readText(i).toString();

      // Save data to the map according to the type indicated in &#39;columnHeaders&#39;
      if (colTypeString.equals(&amp;quot;INTEGER&amp;quot;)) {

        org.apache.drill.exec.expr.holders.IntHolder intHolder = new org.apache.drill.exec.expr.holders.IntHolder();

        intHolder.value = Integer.parseInt(rowString);

        gaMapWriter.integer(colNameString).write(intHolder);
      }
      else if (colTypeString.equals(&amp;quot;TIME&amp;quot;) || colTypeString.equals(&amp;quot;FLOAT&amp;quot;) || colTypeString.equals(&amp;quot;PERCENT&amp;quot;) || colTypeString.equals(&amp;quot;CURRENCY&amp;quot;)) {

        org.apache.drill.exec.expr.holders.Float8Holder floatHolder = new org.apache.drill.exec.expr.holders.Float8Holder();

        floatHolder.value = Float.parseFloat(rowString);

        gaMapWriter.float8(colNameString).write(floatHolder);
      }
      // If it&#39;s not one of these, just treat it as a &amp;quot;STRING&amp;quot;
      else {

        org.apache.drill.exec.expr.holders.VarCharHolder rowHolder = new org.apache.drill.exec.expr.holders.VarCharHolder();

        byte[] rowStringBytes = rowString.getBytes();

        outBuffer.reallocIfNeeded(rowStringBytes.length);
        outBuffer.setBytes(0, rowStringBytes);

        rowHolder.start = 0;
        rowHolder.end = rowStringBytes.length;
        rowHolder.buffer = outBuffer;

        gaMapWriter.varChar(colNameString).write(rowHolder);
      }

      i++;
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;A more detailed explanation of UDF source code is available in the &lt;a href=&#34;https://drill.apache.org/docs/tutorial-develop-a-simple-function/&#34;&gt;Drill
documentation&lt;/a&gt;, but here are the basics: The &amp;lsquo;@Param&amp;rsquo;
annotations indicate variable types for the first and second inputs to the function, and &amp;lsquo;@Output&amp;rsquo; does the same for
(you guessed it) the output. After we set up a Drill buffer with the &amp;lsquo;@Inject&amp;rsquo; line, &amp;lsquo;@FunctionTemplate()&amp;rsquo; specifies
some function behavior, including the name we&amp;rsquo;ll use to invoke it from the command line interface. For this UDF we don&amp;rsquo;t
need to do anything in &amp;lsquo;setup(),&amp;rsquo; but we do need to fill in &amp;lsquo;eval()&amp;rsquo; with code that defines the operation of the
function.&lt;/p&gt;

&lt;p&gt;In the case of GAHELPER(), the function processes the first arugment (the &amp;lsquo;columnHeaders&amp;rsquo; entry of the Google Analytics
JSON), along with the second argument (the &amp;lsquo;rows&amp;rsquo; entry), to output a map of keys and values for each row of the GA
data. Along the way it also determines the variable type from &amp;lsquo;columnHeaders&amp;rsquo; so we can, for example, immediately talk
to integers in the output map like they &lt;em&gt;are&lt;/em&gt; integers instead of having to pass them through a CAST() like we did in the
last article.&lt;/p&gt;

&lt;p&gt;Now build the source by running &lt;code&gt;mvn clean package&lt;/code&gt; in the directory that contains &lt;code&gt;pom.xml&lt;/code&gt;, and then copy the
resulting files to the Drill install:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;cp target/*.jar ~/apache-drill/jars/3rdparty
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now launch &lt;code&gt;drill-embedded&lt;/code&gt; and give it a try. The output of the function (truncated somewhat by hand) has a structure like:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;SELECT GAHELPER(ga_table.columnHeaders,FLATTEN(ga_table.`rows`)) FROM `s3-ga`.`google_analytics_dev_2015-10-19.json`
ga_table;
+--------+
| EXPR$0 |
+--------+
| {&amp;quot;ga:browser&amp;quot;:&amp;quot;Chrome&amp;quot;,&amp;quot;ga:browserVersion&amp;quot;:&amp;quot;39.0.2171.71&amp;quot;,&amp;quot;ga:screenResolution&amp;quot;:&amp;quot;1024x768&amp;quot;,&amp;quot;ga:deviceCategory&amp;quot;:&amp;quot;desktop&amp;quot;,...} |
| {&amp;quot;ga:browser&amp;quot;:&amp;quot;Chrome&amp;quot;,&amp;quot;ga:browserVersion&amp;quot;:&amp;quot;39.0.2171.71&amp;quot;,&amp;quot;ga:screenResolution&amp;quot;:&amp;quot;1024x768&amp;quot;,&amp;quot;ga:deviceCategory&amp;quot;:&amp;quot;desktop&amp;quot;,...} |
| {&amp;quot;ga:browser&amp;quot;:&amp;quot;Chrome&amp;quot;,&amp;quot;ga:browserVersion&amp;quot;:&amp;quot;40.0.2214.111&amp;quot;,&amp;quot;ga:screenResolution&amp;quot;:&amp;quot;(not set)&amp;quot;,&amp;quot;ga:deviceCategory&amp;quot;:&amp;quot;desktop&amp;quot;,...} |
| ... |
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now remember that using only standard Drill functions, the query I ended on last time looked like this:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;  SELECT `Date`, `Hour`, Browser, Version, Resolution, Device, SUM(CAST(Sessions AS INTEGER)) `Total Sessions`
    FROM (SELECT data[4] `Date`, data[5] `Hour`, data[0] Browser, data[1] Version, data[2] Resolution, data[3] Device, data[8] Sessions
            FROM (SELECT FLATTEN(ga_table.`rows`) data
                    FROM `s3-ga`.`google_analytics_dev_2015-10-19.json` ga_table))
GROUP BY `Date`, `Hour`, Browser, Version, Resolution, Device
ORDER BY `Date`, `Hour`;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;But if we use the awesome power of the GAHELPER() UDF, we can perform the same query with:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;  SELECT m.r.`ga:date` `Date`, m.r.`ga:hour` `Hour`, m.r.`ga:browser` Browser, m.r.`ga:browserVersion` Version,
         m.r.`ga:screenResolution` Resolution, m.r.`ga:deviceCategory` Device, SUM(m.r.`ga:sessions`) `Total Sessions`
    FROM (SELECT GAHELPER(ga_table.columnHeaders,FLATTEN(ga_table.`rows`)) AS r
            FROM `s3-ga`.`google_analytics_dev_2015-10-19.json` ga_table) AS m
GROUP BY m.r.`ga:date`, m.r.`ga:hour`, m.r.`ga:browser`, m.r.`ga:browserVersion`, m.r.`ga:screenResolution`, m.r.`ga:deviceCategory`
ORDER BY m.r.`ga:date`, m.r.`ga:hour`;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Note the advantages here! We only need &lt;em&gt;one&lt;/em&gt; subquery now, and we can reference the data directly using intrinsic Google
Analytics names (&amp;lsquo;ga:browserVersion&amp;rsquo;, etc.). In fact, by eliminating the need to manually determine what each index
means (&amp;lsquo;4&amp;rsquo; for &amp;lsquo;Date&amp;rsquo;, or &amp;lsquo;0&amp;rsquo; for &amp;lsquo;Browser&amp;rsquo;) we&amp;rsquo;re skipping a whole step that&amp;rsquo;s implicit in the first query. And don&amp;rsquo;t
forget that now we can call SUM() directly on the sessions count without a preceeding CAST() since GAHELPER() is smart
enough to determine the types of values.&lt;/p&gt;

&lt;p&gt;So that&amp;rsquo;s my whirlwind tour of the custom function capability of Apache Drill. Time to start thinking about how a UDF
could improve your data experience!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Using SQL to interface with Google Analytics data stored on Amazon S3</title>
      <link>/kstirman.github.io/bookshelf/blog/using-SQL-to-interface-with-Google-Analytics-data-stored-on-Amazon-S3/</link>
      <pubDate>Tue, 20 Oct 2015 00:00:00 +0000</pubDate>
      
      <guid>/kstirman.github.io/bookshelf/blog/using-SQL-to-interface-with-Google-Analytics-data-stored-on-Amazon-S3/</guid>
      <description>

&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;In the realm of web analytics, Google&amp;rsquo;s presence remains formidable. And it&amp;rsquo;s no surprise&amp;mdash;as a free service with a
brain-dead easy setup and a wide range of collected user information, Google Analytics has a lot going for it. But if
you&amp;rsquo;d like to move away from the standard Analytics web interface, what are your options? The intended audience for this
article is those who might wish for a little more flexibility with their Google Analytics data.&lt;/p&gt;

&lt;p&gt;An excellent tool for accomplishing this flexibility is Apache Drill. Drill is a piece of open source software that&amp;rsquo;s
capable of providing a standard SQL command-line interface to a wide range of data types stored in a variety of ways. In
this application we&amp;rsquo;ll be using Drill to talk to some JSON data retrieved using the Google Analytics API and stored on
Amazon S3.&lt;/p&gt;

&lt;h2 id=&#34;accessing-the-google-analytics-api-from-python&#34;&gt;Accessing the Google Analytics API from Python&lt;/h2&gt;

&lt;p&gt;Google Analytics can be interfaced via a number of different languages, but in this example we&amp;rsquo;ll constrain ourselves
to the Python API. The necessary files are easily installed via the Python package manager &lt;code&gt;pip&lt;/code&gt; on the command line:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ sudo pip install --upgrade google-api-python-client
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The next step is to generate the credentials necessary to use the Google Analytics API from within a script. To do this
log in to &lt;a href=&#34;http://console.developers.google.com&#34;&gt;console.developers.google.com&lt;/a&gt; and create a new project. With your new project
selected we need to first enable the Analytics API. Click on &amp;ldquo;APIs&amp;rdquo; under &amp;ldquo;APIs &amp;amp; auth&amp;rdquo;, and then select &amp;ldquo;Analytics API&amp;rdquo;
in the &amp;ldquo;Advertising APIs&amp;rdquo; grouping. In the page that shows up next, click &amp;ldquo;Enable API.&amp;rdquo; Now it&amp;rsquo;s time to go to
&amp;ldquo;Credentials&amp;rdquo; on the left column, and click &amp;ldquo;Add credentials.&amp;rdquo; Select &amp;ldquo;Service account&amp;rdquo; from the drop down, and &amp;ldquo;P12&amp;rdquo;
before hitting the &amp;ldquo;Create&amp;rdquo; button.&lt;/p&gt;

&lt;p&gt;This action will download a &lt;code&gt;.p12&lt;/code&gt; file to your computer that we&amp;rsquo;ll need later for the script, and then forward you to a
page with a listing of your service accounts. The email address you see in the left column will need to be added to your
Google Analytics settings. Head over to &lt;a href=&#34;http://analytics.google.com&#34;&gt;analytics.google.com&lt;/a&gt;, click &amp;ldquo;Admin&amp;rdquo; at the top, select
&amp;ldquo;User Management&amp;rdquo; from the left, and then paste the email address you saw listed for your service account into the &amp;ldquo;Add
permissions for:&amp;rdquo; box.  From here just click &amp;ldquo;Add&amp;rdquo; and you&amp;rsquo;re done doing the web configuration necessary for making
Google Analytics to work with a script.&lt;/p&gt;

&lt;p&gt;&lt;br&gt;
&lt;br&gt;
&lt;p style=&#34;text-align: center;&#34;&gt;
&lt;img style=&#34;max-width: 100%;&#34; src=&#34;kstirman.github.io/bookshelf/img/analytics.png&#34;&gt;
&lt;/p&gt;
&lt;p style=&#34;text-align: center; font-style: italic;&#34;&gt;You need to add the email associated with your service account to
your Google Analytics in order to enable API access from the script.&lt;/p&gt;
&lt;br&gt;
&lt;br&gt;&lt;/p&gt;

&lt;h2 id=&#34;using-amazon-s3-from-python&#34;&gt;Using Amazon S3 from Python&lt;/h2&gt;

&lt;p&gt;The example script included in this article will do a couple different things: First, it exposes a specified set of
Google Analytics data as a dump to a JSON file, and second, it uploads this dumped data to the cloud by way of Amazon
S3.  In order for this second task to succeed, we also to need to ensure that the script has access to the necessary
Amazon Web Services credentials by going to &lt;a href=&#34;http://console.aws.amazon.com/iam/home&#34;&gt;console.aws.amazon.com/iam/home&lt;/a&gt;. On this
page click &amp;ldquo;Users&amp;rdquo; on the left, and then select your username from the list that shows up. Then scroll down to the
&amp;ldquo;Security Credentials&amp;rdquo; section and click the button that says &amp;ldquo;Create Access Key.&amp;rdquo; Next hit &amp;ldquo;Download Credentials&amp;rdquo; to
retrieve a file called &lt;code&gt;credentials.csv&lt;/code&gt;.  The values from this file need to be placed in &lt;code&gt;~/.aws/credentials&lt;/code&gt; in the
following way:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[default]
aws_access_key_id = ACCESSKEYID_FROM_CREDENTIALS_CSV
aws_secret_access_key = SECRETACCESSKEY_FROM_CREDENTIALS_CSV
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Finally, you&amp;rsquo;ll need to install the Python package necessary to access your S3 storage via a script:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;pip install boto3
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;example-python-script-for-dumping-google-analytics-to-s3&#34;&gt;Example Python script for dumping Google Analytics to S3&lt;/h2&gt;

&lt;p&gt;Now we&amp;rsquo;re finally ready to take a look at the example script, which I&amp;rsquo;ve called &lt;code&gt;ga_dump.py&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Portions of this code are based heavily on Google&#39;s HelloAnalytics.py exmaple:
# https://developers.google.com/analytics/devguides/reporting/core/v3/quickstart/service-py
# As such, this software is covered under the Apache 2.0 License:
# http://www.apache.org/licenses/LICENSE-2.0

import httplib2
import sys
import json

import boto3

from apiclient.discovery import build
from oauth2client import client, file, tools
from oauth2client.client import SignedJwtAssertionCredentials

# Global variables that hold information relevant to your GA access
ga_key_file_name = &amp;quot;PATH TO YOUR .p12 KEY FILE FROM DEV CONSOLE&amp;quot;
ga_service_email = &amp;quot;SERVICE EMAIL CREATED IN DEV CONSOLE&amp;quot;

# Global variable that holds the name of the S3 bucket that you&#39;re dumping to
my_s3_bucket_name = &amp;quot;NAME OF YOUR AMAZON S3 BUCKET&amp;quot;

# Create a service
def get_ga_service():

  print(&amp;quot;\nConnecting to Google Analytics...\n&amp;quot;)

  f = open(ga_key_file_name, &#39;rb&#39;)
  ga_key = f.read()
  f.close()

  ga_credentials = SignedJwtAssertionCredentials(ga_service_email, ga_key, scope=[&#39;https://www.googleapis.com/auth/analytics.readonly&#39;])

  ga_api_name = &#39;analytics&#39;
  ga_version = &#39;v3&#39;

  ga_service = build(ga_api_name,ga_version, http=ga_credentials.authorize(httplib2.Http()))

  return ga_service

# Get a profile id from the service
# By default gets the id for the the first account, property, and view
def get_ga_id(ga_service, acc_num = 0, prop_num = 0, view_num = 0):  

  print(&amp;quot;Using the following settings:\n&amp;quot;)

  try:
    acc = ga_service.management().accounts().list().execute().get(&#39;items&#39;)[acc_num]
    acc_id = acc.get(&#39;id&#39;)
    print(&amp;quot;Google Analytics account: &amp;quot; + acc.get(&#39;name&#39;))

  except:
    print(&amp;quot;Error finding account&amp;quot;)
    return None

  try:
    prop = ga_service.management().webproperties().list(accountId=acc_id).execute().get(&#39;items&#39;)[prop_num]
    prop_id = prop.get(&#39;id&#39;)
    print(&amp;quot;Property name: &amp;quot; + prop.get(&#39;name&#39;))
  except:
    print(&amp;quot;Error finding property&amp;quot;)
    return None

  try:
    view = ga_service.management().profiles().list(accountId=acc_id,webPropertyId=prop_id).execute().get(&#39;items&#39;)[view_num]
    view_id = view.get(&#39;id&#39;)
    print(&amp;quot;Analytics view name: &amp;quot; + view.get(&#39;name&#39;) +&amp;quot;\n&amp;quot;)
  except:
    print(&amp;quot;Error finding view&amp;quot;)
    return None

  return view_id

def pretty_json(obj):
  return json.dumps(obj, sort_keys=True, separators=(&#39;,&#39;,&#39;:&#39;), indent=4)

# Dumps to three files:
# One for geographic (geo) data, one for data about acquisition (acq), and another about devices used (ev)
def fetch_and_dump(ga_service,ga_id):

  # Google Analytics metrics we want
  ga_metrics = &#39;ga:users,\
                ga:newusers,\
                ga:sessions,\
                ga:bounces,\
                ga:sessionDuration,\
                ga:hits&#39;

  dims_date = &#39;,ga:date,ga:hour&#39;

  # Sets of dimensions to look at
  ga_dims_geo = &#39;ga:country,\
                 ga:region,\
                 ga:city,\
                 ga:continent,\
                 ga:language&#39;+dims_date

  ga_dims_acq = &#39;ga:source,\
                 ga:medium,\
                 ga:socialNetwork&#39;+dims_date

  ga_dims_dev = &#39;ga:browser,\
                 ga:browserVersion,\
                 ga:screenResolution,\
                 ga:deviceCategory&#39;+dims_date




  data_geo = ga_service.data().ga().get(ids=&#39;ga:&#39;+ga_id,start_date=sys.argv[1], end_date=sys.argv[1], metrics=ga_metrics, dimensions=ga_dims_geo).execute()
  data_acq = ga_service.data().ga().get(ids=&#39;ga:&#39;+ga_id,start_date=sys.argv[1], end_date=sys.argv[1], metrics=ga_metrics, dimensions=ga_dims_acq).execute()
  data_dev = ga_service.data().ga().get(ids=&#39;ga:&#39;+ga_id,start_date=sys.argv[1], end_date=sys.argv[1], metrics=ga_metrics, dimensions=ga_dims_dev).execute()

  file_geo = &#39;google_analytics_geo_&#39;+sys.argv[1]+&#39;.json&#39;
  file_acq = &#39;google_analytics_acq_&#39;+sys.argv[1]+&#39;.json&#39;
  file_dev = &#39;google_analytics_dev_&#39;+sys.argv[1]+&#39;.json&#39;

  f_geo = open(file_geo,&#39;w&#39;)
  f_acq = open(file_acq,&#39;w&#39;)
  f_dev = open(file_dev,&#39;w&#39;)

  f_geo.write(pretty_json(data_geo))
  f_acq.write(pretty_json(data_acq))
  f_dev.write(pretty_json(data_dev))

  f_geo.close()
  f_acq.close()
  f_dev.close()

  # return a list of the dump files
  file_list = [file_geo, file_acq, file_dev]

  return file_list

# Upload dumped files to Amazon cloud storage
def upload_to_s3(file_list):
  aws_s3 = boto3.resource(&#39;s3&#39;)

  # Make a bucket if we need to
  aws_s3.create_bucket(Bucket=my_s3_bucket_name)

  for file_name in file_list:
    aws_s3.Bucket(my_s3_bucket_name).put_object(Key=file_name, Body = open(file_name, &#39;rb&#39;))

# Main program execution
my_service = get_ga_service()

if my_service == None:
  print(&amp;quot;Error connecting to Google Analytics!&amp;quot;)

else:
  my_id = get_ga_id(my_service)

  print(&amp;quot;Dumping Analytics data to files...&amp;quot;)
  files = fetch_and_dump(my_service,my_id)
  print(&amp;quot;Done!&amp;quot;)

  print(&amp;quot;\nUploading to Amazon S3 storage...&amp;quot;)
  upload_to_s3(files)
  print(&amp;quot;Done!&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The script takes a single command line argument: an ISO 8601 formatted date that specifies which day to dump Google
Analytics data from. For instance to retrieve the previous day&amp;rsquo;s data, you could run:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ python ga-dump.py `date -v -1d &amp;quot;+%Y-%m-%d&amp;quot;`
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;One possible use case would involve running this command at regular intervals via the unix cron daemon. As written, the
script outputs three JSON files: one for visitor geographic data, one for visitor acquisition data, and one for data
about the kinds of devices visitors are using.&lt;/p&gt;

&lt;p&gt;Before running, don&amp;rsquo;t forget to change the global variables at the top of the listing to match your Google Analytics
credentials and S3 bucketname! (Also: users of OS X will need to implement &lt;a href=&#34;https://developers.google.com/gmail/api/quickstart/python#troubleshooting&#34;&gt;this
fix&lt;/a&gt; before the script can run).&lt;/p&gt;

&lt;h2 id=&#34;setting-up-apache-drill-for-use-with-s3&#34;&gt;Setting up Apache Drill for use with S3&lt;/h2&gt;

&lt;p&gt;Now that we can toss dumps of Google Analytics up to the AWS cloud without much effort, it&amp;rsquo;s time to implement Drill as
an SQL interface to the data. Installing Drill itself is an extremely &lt;a href=&#34;https://drill.apache.org/docs/installing-drill-on-linux-and-mac-os-x/&#34;&gt;simple
process&lt;/a&gt; (all you need is Java and the Drill
tarball), but we&amp;rsquo;ll need to do a little configuration in order to talk to our S3 bucket.&lt;/p&gt;

&lt;p&gt;First, edit the file &lt;code&gt;core-site.xml&lt;/code&gt; in the &lt;code&gt;./conf&lt;/code&gt; directory of the Drill install, replacing the relevant parts with
your Amazon S3 credentials:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;configuration&amp;gt;

    &amp;lt;property&amp;gt;
        &amp;lt;name&amp;gt;fs.s3a.access.key&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;ENTER_YOUR_ACCESSKEY&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;

    &amp;lt;property&amp;gt;
        &amp;lt;name&amp;gt;fs.s3a.secret.key&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;ENTER_YOUR_SECRETKEY&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;

&amp;lt;/configuration&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Next, start up the embdedded (single machine) version of Drill&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;~/apache-drill/bin/drill-embedded
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;so we can use the Drill Web Console located at &lt;a href=&#34;http://localhost:8047&#34;&gt;http://localhost:8047&lt;/a&gt;. We&amp;rsquo;ll proceed by making a copy of the &amp;lsquo;dfs&amp;rsquo;
storage plugin. To do this go to the &amp;lsquo;Storage&amp;rsquo; page, and hit &amp;lsquo;Update&amp;rsquo; next to &amp;lsquo;dfs&amp;rsquo;, making a copy of the text
listed in the &amp;ldquo;Configuration&amp;rdquo; box that&amp;rsquo;s displayed on the next page. Now type a name for our new S3 plugin into the &amp;ldquo;New
Storage Plugin&amp;rdquo; box at the bottom of the previous page (&amp;ldquo;s3-ga&amp;rdquo; might make a good choice). Place the text for the &amp;lsquo;dfs&amp;rsquo;
plugin into the box, editing &lt;code&gt;&amp;quot;connection&amp;quot;: &amp;quot;file:///&amp;quot;&lt;/code&gt; so that it specifies S3 and the name of your bucket instead, as
in &lt;code&gt;&amp;quot;connection&amp;quot;: &amp;quot;s3a://example.bucketname&amp;quot;&lt;/code&gt;. Hit &amp;ldquo;Create&amp;rdquo; to make the plugin.&lt;/p&gt;

&lt;h2 id=&#34;querying-google-analytics-json-with-apache-drill&#34;&gt;Querying Google Analytics JSON with Apache Drill&lt;/h2&gt;

&lt;p&gt;Now we&amp;rsquo;re ready to start querying our Google Analytics JSON using Drill! Try a simple &lt;code&gt;SELECT *&lt;/code&gt; from the &lt;code&gt;drill-embedded&lt;/code&gt; prompt:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt; SELECT * FROM `s3-ga`.`google_analytics_geo_2015-10-19.json`;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You may notice that the results of this query are not exactly&amp;hellip; beautiful. This is because the structure of a Google
Analytics JSON dump isn&amp;rsquo;t compatible with simple queries like this. And that&amp;rsquo;s okay! We can easily work around that with
some slightly more sophisticated SQL (Hey, if you wanted easy you&amp;rsquo;d be using the web interface, right?).&lt;/p&gt;

&lt;p&gt;To list information about the columns of our data set, we can use the following command:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt; SELECT ROW_NUMBER() OVER(ORDER BY 1) - 1 AS `Column Index`, KVGEN(FLATTEN(ga_table.columnHeaders))[2] AS `Column Info`
&amp;gt; FROM `s3-ga`.`google_analytics_geo_2015-10-19.json` ga_table;
+---------------+----------------------------------------------+
| Column Index  |                 Column Info                  |
+---------------+----------------------------------------------+
| 0             | {&amp;quot;key&amp;quot;:&amp;quot;name&amp;quot;,&amp;quot;value&amp;quot;:&amp;quot;ga:country&amp;quot;}          |
| 1             | {&amp;quot;key&amp;quot;:&amp;quot;name&amp;quot;,&amp;quot;value&amp;quot;:&amp;quot;ga:region&amp;quot;}           |
| 2             | {&amp;quot;key&amp;quot;:&amp;quot;name&amp;quot;,&amp;quot;value&amp;quot;:&amp;quot;ga:city&amp;quot;}             |
| 3             | {&amp;quot;key&amp;quot;:&amp;quot;name&amp;quot;,&amp;quot;value&amp;quot;:&amp;quot;ga:continent&amp;quot;}        |
| 4             | {&amp;quot;key&amp;quot;:&amp;quot;name&amp;quot;,&amp;quot;value&amp;quot;:&amp;quot;ga:language&amp;quot;}         |
| 5             | {&amp;quot;key&amp;quot;:&amp;quot;name&amp;quot;,&amp;quot;value&amp;quot;:&amp;quot;ga:date&amp;quot;}             |
| 6             | {&amp;quot;key&amp;quot;:&amp;quot;name&amp;quot;,&amp;quot;value&amp;quot;:&amp;quot;ga:hour&amp;quot;}             |
| 7             | {&amp;quot;key&amp;quot;:&amp;quot;name&amp;quot;,&amp;quot;value&amp;quot;:&amp;quot;ga:users&amp;quot;}            |
| 8             | {&amp;quot;key&amp;quot;:&amp;quot;name&amp;quot;,&amp;quot;value&amp;quot;:&amp;quot;ga:newusers&amp;quot;}         |
| 9             | {&amp;quot;key&amp;quot;:&amp;quot;name&amp;quot;,&amp;quot;value&amp;quot;:&amp;quot;ga:sessions&amp;quot;}         |
| 10            | {&amp;quot;key&amp;quot;:&amp;quot;name&amp;quot;,&amp;quot;value&amp;quot;:&amp;quot;ga:bounces&amp;quot;}          |
| 11            | {&amp;quot;key&amp;quot;:&amp;quot;name&amp;quot;,&amp;quot;value&amp;quot;:&amp;quot;ga:sessionDuration&amp;quot;}  |
| 12            | {&amp;quot;key&amp;quot;:&amp;quot;name&amp;quot;,&amp;quot;value&amp;quot;:&amp;quot;ga:hits&amp;quot;}             |
+---------------+----------------------------------------------+
13 rows selected (1.739 seconds)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And now that we know the column index for &amp;lsquo;ga:city&amp;rsquo; is &amp;lsquo;2&amp;rsquo; we can use this query to inspect what cities visitors came
from on the date of the file:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt; SELECT DISTINCT FLATTEN(ga_table.`rows`)[2] AS Cities FROM `s3-ga`.`google_analytics_geo_2015-10-19.json` ga_table;
+-------------+
|   Cities    |
+-------------+
| (not set)   |
| Almaty      |
| Pushkino    |
| Samara      |
| Seoul       |
| Tolyatti    |
| Tula        |
| Volgodonsk  |
+-------------+
8 rows selected (1.292 seconds)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This simple example is fine, but as I pointed out before the advantage of this approach is the flexibility you gain in
making queries. So let&amp;rsquo;s set our sights on doing something that&amp;rsquo;s impossible to accomplish even in the &amp;lsquo;Custom Reports&amp;rsquo;
interface of the Google Analytics web GUI: inspecting more than 5 analysis dimensions simultaneously.&lt;/p&gt;

&lt;p&gt;The following statement asks for the total number of sessions along the dimensions of date, hour, browser name, browser
version, screen resolution, and type of device. Formulating a statement that analyzes several columns of data is
somewhat more complicated than our previous single-column example, and I ended up constructing mine out of two
subqueries:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;  SELECT `Date`, `Hour`, Browser, Version, Resolution, Device, SUM(CAST(Sessions AS INTEGER)) `Total Sessions`
    FROM (SELECT data[4] `Date`, data[5] `Hour`, data[0] Browser, data[1] Version, data[2] Resolution, data[3] Device, data[8] Sessions
            FROM (SELECT FLATTEN(ga_table.`rows`) data
                    FROM `s3-ga`.`google_analytics_dev_2015-10-19.json` ga_table))
GROUP BY `Date`, `Hour`, Browser, Version, Resolution, Device
ORDER BY `Date`, `Hour`;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Here the innermost query FLATTENs the data while the next one picks out columns and assigns them names. The main
query handles tallying the total sessions and organizing the data.&lt;/p&gt;

&lt;p&gt;Unfortunately my personal site doesn&amp;rsquo;t get enough traffic to take advantage of the GROUP BY, but the results look like
this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;+-----------+-------+------------+-----------------+-------------+----------+-----------------+
|   Date    | Hour  |  Browser   |     Version     | Resolution  |  Device  | Total Sessions  |
+-----------+-------+------------+-----------------+-------------+----------+-----------------+
| 20151019  | 03    | Safari     | 8.0             | 1366x768    | mobile   | 1               |
| 20151019  | 04    | YaBrowser  | 44.0.2403.3043  | 1024x768    | desktop  | 1               |
| 20151019  | 04    | Chrome     | 40.0.2214.111   | (not set)   | desktop  | 2               |
| 20151019  | 05    | YaBrowser  | 44.0.2403.3043  | 1024x768    | desktop  | 1               |
| 20151019  | 07    | Safari     | 8.0             | 1366x768    | mobile   | 1               |
| 20151019  | 10    | Chrome     | 39.0.2171.71    | 1024x768    | desktop  | 1               |
| 20151019  | 10    | Safari     | 8.0             | 1366x768    | mobile   | 1               |
| 20151019  | 11    | Safari     | 8.0             | 1366x768    | mobile   | 1               |
| 20151019  | 12    | Safari     | 8.0             | 1366x768    | mobile   | 0               |
| 20151019  | 12    | Chrome     | 46.0.2490.71    | 1024x768    | desktop  | 1               |
| 20151019  | 13    | Safari     | 8.0             | 1366x768    | mobile   | 1               |
| 20151019  | 14    | Safari     | 8.0             | 1366x768    | mobile   | 1               |
| 20151019  | 15    | Safari     | 8.0             | 1366x768    | mobile   | 1               |
| 20151019  | 16    | Safari     | 8.0             | 1366x768    | mobile   | 1               |
| 20151019  | 18    | Safari     | 8.0             | 1366x768    | mobile   | 1               |
| 20151019  | 19    | Safari     | 8.0             | 1366x768    | mobile   | 1               |
| 20151019  | 21    | Safari     | 8.0             | 1366x768    | mobile   | 2               |
| 20151019  | 21    | Chrome     | 39.0.2171.71    | 1024x768    | desktop  | 1               |
+-----------+-------+------------+-----------------+-------------+----------+-----------------+
18 rows selected (2.086 seconds)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;While it&amp;rsquo;s definitely possible to interface with the data this way, Apache Drill offers an alternative solution in the
form of custom user defined functions. In my &lt;a href=&#34;kstirman.github.io/bookshelf/blog/querying-google-analytics-json-with-a-custom-sql-function/&#34;&gt;next
post&lt;/a&gt;, I&amp;rsquo;ll show you how to implement a
GAHELPER() function that makes working with Google Analytics data from the Drill command line significantly easier.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>